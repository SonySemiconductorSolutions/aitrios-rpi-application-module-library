"use strict";(self.webpackChunkmodlib_docs=self.webpackChunkmodlib_docs||[]).push([[9992],{2255:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"examples/instance_segmentation","title":"Instance Segmentation","description":"The Instance Segmentation component is part of the Segments result class and is designed to identify turn segmentation results into instance segmentation results. It does this by taking the mask of each class and running a Connected Component Analysis (CCA), to get the masks of separated objects. Then to deal with overlapping objects a Watershed algorithm is applied to improve the results of the instance segmentation. From these instance segmentation results you can calculate the bounding boxes or oriented bounding boxes, allowing you to connect Segments to many other modules like Tracker or Matcher.","source":"@site/_docs_versioned_docs/version-1.1.0/examples/instance_segmentation.md","sourceDirName":"examples","slug":"/examples/instance_segmentation","permalink":"/en/application-module-library/docs/examples/instance_segmentation","draft":false,"unlisted":false,"tags":[],"version":"1.1.0","lastUpdatedAt":1750065085000,"sidebarPosition":9,"frontMatter":{"title":"Instance Segmentation","sidebar_position":9},"sidebar":"tutorialSidebar","previous":{"title":"Motion","permalink":"/en/application-module-library/docs/examples/motion"},"next":{"title":"Release Notes","permalink":"/en/application-module-library/docs/release_notes"}}');var o=n(4848),a=n(8453);n(6036);const i={title:"Instance Segmentation",sidebar_position:9},r="Instance Segmentation",c={},l=[];function d(e){const t={a:"a",code:"code",h1:"h1",header:"header",img:"img",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"instance-segmentation",children:"Instance Segmentation"})}),"\n",(0,o.jsxs)("div",{style:{display:"flex",gap:"2rem",alignItems:"flex-start"},children:[(0,o.jsx)("div",{style:{flex:"1"},children:(0,o.jsxs)(t.p,{children:["The Instance Segmentation component is part of the Segments result class and is designed to identify turn segmentation results into instance segmentation results. It does this by taking the mask of each class and running a ",(0,o.jsx)(t.a,{href:"https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#gaedef8c7340499ca391d459122e51bef5",children:"Connected Component Analysis (CCA)"}),", to get the masks of separated objects. Then to deal with overlapping objects a ",(0,o.jsx)(t.a,{href:"https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html",children:"Watershed"})," algorithm is applied to improve the results of the instance segmentation. From these instance segmentation results you can calculate the bounding boxes or oriented bounding boxes, allowing you to connect Segments to many other modules like Tracker or Matcher."]})}),(0,o.jsx)("div",{style:{flex:"1"},children:(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Instance",src:n(7189).A+"",width:"800",height:"450"})})})]}),"\n",(0,o.jsx)(t.p,{children:"Below an example of how one can use a Segments models to produce Instance Segmentation results in the Application Module Library."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",metastring:'title="instance_segment.py"',children:'from modlib.apps import Annotator\nfrom modlib.devices import AiCamera\nfrom modlib.models.zoo import DeepLabV3Plus\nfrom modlib.devices.frame import IMAGE_TYPE\n\n\nclass InstanceSegArgs:\n    erosion_kernel: int = 3\n    erosion_iteration: int = 2\n    dilate_kernel: int = 5\n    dilate_iteration: int = 5\n    dist_threshold: float = 0.05\n    size_threshold: int = 100\n    config_mode = False\n\n\ndevice = AiCamera()\nmodel = DeepLabV3Plus()\ndevice.deploy(model)\n\nannotator = Annotator()\n\nwith device as stream:\n    for frame in stream:\n        detections = frame.detections\n        if frame.image_type != IMAGE_TYPE.INPUT_TENSOR:\n            detections.compensate_for_roi(frame.roi)\n        instance_masks = detections.instance_segmentation(frame.width, frame.height, InstanceSegArgs)\n        oriented_bboxes = detections.oriented_bbox()\n\n        labels = [f"Class: {c}" for c, _, _, _ in detections]\n        annotator.annotate_instance_segments(frame, detections)\n        annotator.annotate_oriented_boxes(frame, detections, labels)\n        frame.display()\n'})}),"\n",(0,o.jsxs)(t.p,{children:["Changing the ",(0,o.jsx)(t.code,{children:"InstanceSegArgs"})," will allow you to fine-tune the algorithms for the situation. Enabling ",(0,o.jsx)(t.code,{children:"config_mode"})," will allow you to visualize the effects of changing the different parameter values to see the difference the parameters make."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Instance Segmentation: config_mode",src:n(8893).A+"",width:"1509",height:"662"})}),"\n",(0,o.jsxs)(t.p,{children:["Increasing the erosion and dilate kernel sizes or the iterations will change the masks so that they get smaller making it easier to calculate the different instances with the Watershed algorithm. The ",(0,o.jsx)(t.code,{children:"dist_thrreshold"})," parameter will directly impact the distances matrix image you can see. Decreasing the threshold will allow objects that are closer together be more defined in the foreground. Then ",(0,o.jsx)(t.code,{children:"size_threshold"})," sets the minimum mask size so that small masks don't get detected."]})]})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},6036:(e,t,n)=>{n.d(t,{A:()=>r});n(6540);var s=n(8774),o=n(3025),a=n(4070),i=n(4848);function r({to:e,children:t,...n}){const r=(0,o.r)("_docs")?.label||"latest",c=(0,a.ir)("_docs"),l=c?.isLast;let d=e;return e.startsWith("/api-reference/")&&(l||(d=`/api-reference/${r}${e.replace("/api-reference","")}`)),(0,i.jsx)(s.A,{to:d,...n,children:t})}},7189:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/instance-25b733cae67f61617544505614ba8e20.gif"},8893:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/instance_segmentation-6478677c65dbeb60c86a8177d280a720.jpg"},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>r});var s=n(6540);const o={},a=s.createContext(o);function i(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);